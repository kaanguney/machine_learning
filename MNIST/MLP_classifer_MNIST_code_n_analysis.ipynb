{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KAAN GÜNEY KEKLİKÇİ - 24986"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multilayer Perceptron Classifier for MNIST dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **********************************\n",
    "### *** Requirements for Multilayer Perceptron Classifier(MLP) ***\n",
    "        - we need to scale our data between 0&1(that's how A-NN's work)\n",
    "        - we need to export the data from files with .ubyte extension\n",
    "        - we need to repeat this process for the following 4 files which are:\n",
    "            - t10k-images-idx3-ubyte\n",
    "            - t10k-labels-idx1-ubyte\n",
    "            - train-images-idx3-ubyte\n",
    "            - train-labels-idx1-ubyte\n",
    "**********************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporting the dataset from the above-mentioned files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # import necessary libraries \n",
    "import struct\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "%matplotlib inline\n",
    "import sys as py_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementing a function for extraction, data conversion and "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_convert():\n",
    "    with open('./train-labels-idx1-ubyte', 'rb') as binary_file: # process the labels for the training sample\n",
    "        binary_file.seek(0)  # return to the beginning of the file\n",
    "        # Reading first 4 bytes to extract the magic number\n",
    "        magic_number = binary_file.read(4)\n",
    "        # unpacking couple_bytes as a 4byte signed integer with Big-endian Byte order\n",
    "        train_magic_number = struct.unpack('>i',magic_number) \n",
    "        # print(magic_number)\n",
    "        # unpacking next 4 bytes to extract the number of items\n",
    "        nitems = binary_file.read(4)\n",
    "        nitems = struct.unpack('>i',nitems)\n",
    "        # print(nitems)\n",
    "        # Next, we use np.fromfile to create an array from data in a binary file(var)\n",
    "        train_labels = np.fromfile(binary_file, np.uint8) # labels are an unsigned byte --> np.uint8 \n",
    "        # print (train_labels)\n",
    "    with open('./train-images-idx3-ubyte', 'rb') as binary_file: # processing training images\n",
    "        # reading the first 16 bytes: \n",
    "        # 4bytes: magic_number | 4bytes: # of images | 4bites: # of rows | 4bytes: # of cols\n",
    "        data = binary_file.read(16) \n",
    "        magic_number, ntrimages, rows, cols = struct.unpack('>iiii', data)\n",
    "        # print (magic_number, ntrimages, rows, cols)\n",
    "        # extracting images and storing them into a numpy array (note that each image is stored as a vector, so we need to reshape it in the matrix form)\n",
    "        train_images = np.fromfile(binary_file, np.uint8).reshape(ntrimages, rows, cols)\n",
    "    with open('./t10k-labels-idx1-ubyte', 'rb') as binary_file:\n",
    "        data = binary_file.read(8)\n",
    "        magic_number, ntelabels = struct.unpack('>ii',data)\n",
    "        # print (magic_number, ntelabels)\n",
    "        test_labels = np.fromfile(binary_file, np.uint8) # reading the labels\n",
    "    with open('./t10k-images-idx3-ubyte', 'rb') as binary_file:\n",
    "        data = binary_file.read(16)\n",
    "        magic_number, nteimages, rows, cols = struct.unpack('>iiii', data)\n",
    "        # print (magic_number, nteimages, rows, cols)\n",
    "        test_images = np.fromfile(binary_file, np.uint8).reshape(nteimages, rows, cols)\n",
    "    return train_images, train_labels, ntrimages, test_images, test_labels, nteimages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, train_labels, ntrimages, test_images, test_labels, nteimages = read_and_convert()                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_images[7], cmap=cm.Greys) # print an example to see if correctly processed and converted \n",
    "plt.title(train_labels[7])\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*****************************************\n",
    "### *** Before carrying on, check the sample sizes and row-column numbers for both sets *** \n",
    "    - training set(60K datapoints)\n",
    "    - test set(10K datapoints)\n",
    "*****************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape:  (60000, 28, 28)\n",
      "Test data shape:  (10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training data shape: \", train_images.shape) # (60000, 28, 28) -- 60000 images, each 28x28 pixels\n",
    "print(\"Test data shape: \", test_images.shape) # (10000, 28, 28) -- 10000 images, each 28x28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten the images\n",
    "# this means reduce dimensionality into a single vector for each attribute\n",
    "# then compose these vectors and take the transpose to recreate the whole dataset in desired format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "colsize = 28*28\n",
    "train_images = train_images.reshape(train_images.shape[0], colsize)\n",
    "test_images = test_images.reshape(test_images.shape[0], colsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data new format:  (60000, 784)\n",
      "Test data shape:  (10000, 784)\n"
     ]
    }
   ],
   "source": [
    "# check to see if dimensions are now in desired format \n",
    "print(\"Training data new format: \", train_images.shape)\n",
    "print(\"Test data shape: \", test_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now, I have created the matrices for both the training set and the test set\n",
    "# column number is 784, row number is the sample size for each set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*****************************************\n",
    "### *** IMPORTANT *** \n",
    "    - all elements of the array are now integers\n",
    "    - if we keep up with the neural network like this, we will make a horrible mistake because\n",
    "        - we are making predictions on categorical data\n",
    "        - if we use numeric datapoints, we will obtain wrong results\n",
    "    - let's address this with an example;\n",
    "    - prediction:6 output:7 vs prediction:6 output:0\n",
    "    - In our research, both are EQUALLY wrong because we simply guessed wrong pixel value, so our errors are same\n",
    "    - if numeric, errors would be -1 and 6.\n",
    "*****************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dtype: uint8  Test dtype: uint8\n"
     ]
    }
   ],
   "source": [
    "# let's check if we need to convert the elements to categorical data\n",
    "print(\"Train dtype:\",train_images.dtype, \" Test dtype:\",test_images.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yes we do, because they are integer values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to address this;\n",
    "# we will encode single 1(hot-value) digits for every row and remain the other digits as 0s.\n",
    "# in other words, we will use \"one-hot encoded vector\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras  #  again import necessary libraries\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from matplotlib import pyplot as plt\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utilize the categorical changes here \n",
    "# here convert class vectors to binary but categorical matrices - CRUCIAL FOR ERROR CALCULATION\n",
    "num_classes = 10 \n",
    "train_labels = keras.utils.to_categorical(train_labels, num_classes) # y_train\n",
    "test_labels = keras.utils.to_categorical(test_labels, num_classes) # y_test\n",
    "# remark, now the labels are BINARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set-size: 600000  Test set-size: 100000\n"
     ]
    }
   ],
   "source": [
    "# check the size to see if correctly converted\n",
    "print(\"Train set-size:\",train_labels.size, \" Test set-size:\",test_labels.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first 3 hot-values after conversion in each row are visible in the given matrix [[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# futhermore, display a sample of 3 rows to see the hot-value for each row\n",
    "print(\"The first 3 hot-values after conversion in each row are visible in the given matrix\", train_labels[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now, the desired output vs real output could be eaxmined with respect to oour first set splits\n",
    "# necessary conversions above made this possible so far"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*****************************************\n",
    "### *** ARCHITECTURE OF THE MODEL *** \n",
    "    - How many hidden layers? (2 in this case)\n",
    "    - How many nodes in each layer? (300-100 and 100-50 resprectively for 2 tryouts)\n",
    "    - Which activation function for each layer? (sigmoid and softmax)\n",
    "    - The loss functions is chosen as categorical cross entropy.\n",
    "    - SGD - (scholastic gradient descent) is our optimizer - \"error decreaser\"\n",
    "*****************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remark about softmax;\n",
    "    # all values are between 0&1.\n",
    "    # the sum of all ten values is 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In machine learning, softmax is almost always used when the output is one-hot encoded vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now, we can utilize a reusable function and then carry out the both try-outs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dense(layer_sizes):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(layer_sizes[0], activation='sigmoid', input_shape=(colsize,), kernel_initalizer=\"uniform\")) # only for input layer \n",
    "    \n",
    "    for i in layer_sizes[1:]: # after the input layer \n",
    "        model.add(Dense(units=i, activation='sigmoid')) # no need to specify input parameter for hidden layers\n",
    "    \n",
    "    # now, for the output layer \n",
    "    model.add(Dense(units=num_classes, activation='softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, batch_size=128, epochs=5):\n",
    "    model.summary()\n",
    "    model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    history = model.fit(train_images, train_labels, batch_size=batch_size, epochs=epochs, validation_split=.1, verbose=True)\n",
    "    loss, accuracy  = model.evaluate(test_images, test_labels)\n",
    "\n",
    "    print(f'Test loss: {loss:.3}')\n",
    "    print(f'Test accuracy: {accuracy:.3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *** 300-100, 2 hidden layers, sigmoid and softmax activation functions, try-out 1 ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_15 (Dense)             (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/5\n",
      "54000/54000 [==============================] - 2s 43us/sample - loss: 1.8007 - accuracy: 0.6068 - val_loss: 1.3326 - val_accuracy: 0.8110\n",
      "Epoch 2/5\n",
      "54000/54000 [==============================] - 2s 33us/sample - loss: 1.1059 - accuracy: 0.8185 - val_loss: 0.8419 - val_accuracy: 0.8762\n",
      "Epoch 3/5\n",
      "54000/54000 [==============================] - 2s 33us/sample - loss: 0.7704 - accuracy: 0.8612 - val_loss: 0.6087 - val_accuracy: 0.8980\n",
      "Epoch 4/5\n",
      "54000/54000 [==============================] - 2s 38us/sample - loss: 0.5986 - accuracy: 0.8799 - val_loss: 0.4844 - val_accuracy: 0.9092\n",
      "Epoch 5/5\n",
      "54000/54000 [==============================] - 2s 34us/sample - loss: 0.5006 - accuracy: 0.8916 - val_loss: 0.4127 - val_accuracy: 0.9155\n",
      "10000/10000 [==============================] - 0s 49us/sample - loss: 0.4516 - accuracy: 0.9009\n",
      "Test loss: 0.452\n",
      "Test accuracy: 0.901\n"
     ]
    }
   ],
   "source": [
    "model = create_dense([300, 100])\n",
    "evaluate(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *** Accuracy Results on Test&Validation for 300-100 try-out displayed above *** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################################3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *** 100-50, 2 hidden layers, sigmoid and softmax activation functions, try-out 2 ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_18 (Dense)             (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 84,060\n",
      "Trainable params: 84,060\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/5\n",
      "54000/54000 [==============================] - 2s 29us/sample - loss: 2.0336 - accuracy: 0.5055 - val_loss: 1.7769 - val_accuracy: 0.7227\n",
      "Epoch 2/5\n",
      "54000/54000 [==============================] - 1s 23us/sample - loss: 1.5979 - accuracy: 0.7197 - val_loss: 1.3746 - val_accuracy: 0.8048\n",
      "Epoch 3/5\n",
      "54000/54000 [==============================] - 1s 22us/sample - loss: 1.2491 - accuracy: 0.7878 - val_loss: 1.0573 - val_accuracy: 0.8423\n",
      "Epoch 4/5\n",
      "54000/54000 [==============================] - 2s 31us/sample - loss: 0.9866 - accuracy: 0.8329 - val_loss: 0.8330 - val_accuracy: 0.8775\n",
      "Epoch 5/5\n",
      "54000/54000 [==============================] - 1s 26us/sample - loss: 0.8040 - accuracy: 0.8597 - val_loss: 0.6801 - val_accuracy: 0.8950\n",
      "10000/10000 [==============================] - 1s 65us/sample - loss: 0.7158 - accuracy: 0.8779\n",
      "Test loss: 0.716\n",
      "Test accuracy: 0.878\n"
     ]
    }
   ],
   "source": [
    "model = create_dense([100, 50]) \n",
    "evaluate(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now, accuracies and loss functions for both models have been calculated\n",
    "# let's move on to the overall analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ->Multilayer Perceptron Classifer Final Analysis\n",
    "        \n",
    "******************************************\n",
    "- **WORKFLOW** :\n",
    "******************************************\n",
    "    - First, in order to make necessary conversions for the two separate MLP classifiers;\n",
    "        - .gz extensions were unzipped, and with import of structs, MNIST dataset was assigned to;\n",
    "            - x_train, x_test, y_train, y_test sets separately, of course with different names.\n",
    "    - Then, since MNIST consists of 28*28 pixels, the datasets were reshaped using reshape().\n",
    "    - colsizes were now 784 and rows were as much as the size of the samples.(i.e transpose matrices)\n",
    "    - later, one-hot encoded vector was utilized in order to convert numeric values to categorical values, hence,\n",
    "        - we would now obtain an accurate loss function.We are not calculating mathematical difference here,\n",
    "            - we are simply checking if our prediction is on point or not.\n",
    "    - All datapoints are binary at this point.\n",
    "    - Now, we have come to the network architecture.\n",
    "******************************************\n",
    "\n",
    "******************************************\n",
    "- **ARCHITECTURE & CALCULATIONS** :\n",
    "******************************************\n",
    "    - Here, I have created a virtual environment to install tensorflow, one of the four backends of Keras.\n",
    "    - Then keras was imported from tensorflow.\n",
    "    - MLP (multilayer perceptron) relies on different properties such as\n",
    "        - nodes in a layer\n",
    "        - how many layers\n",
    "        - how many epochs \n",
    "        - batch sizes\n",
    "        - activation functions and much more...\n",
    "    - for the purposes of this work, I utilized sigmoid for layers except output layer,\n",
    "        - and for output layer, softmax was utilized.(because one-hot encoded vector was used)\n",
    "    - Others were assigned for the functions as hyperparameters, code is accesible above.\n",
    "    - 300-100, try-out 1 had lower loss function value, so, higher accuracy compared to try-out 2 100-50.\n",
    "    - All of this work is coded above but the idea is more important.\n",
    "    \n",
    "    !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "    - SGD (scholastic gradient descent) was the common optimizer\n",
    "    - categorical_crossentropy was the common loss function\n",
    "    - metric was accuracy\n",
    "    - Gradient descent determines how error changes as epochs work through with respect to every variable.\n",
    "    - Derivative of errors with respect to weights by chain rule, gives this descent.\n",
    "    - Subtraction of this rate of change from the weights to adjust the ANN's, optimizes the weights \n",
    "    to produce even better results.\n",
    "    !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "    \n",
    "******************************************\n",
    "- **PERSONAL REMARK** :\n",
    "******************************************\n",
    "    - Around 90% accuracy and value of at most 0.72 considering both cases at loss functions are pretty good results.\n",
    "    - If activation function sigmoid is changed to RELU, similar to hyperbolic tangent, maybe with more preprocessing,\n",
    "    these accuracies could get very higher.\n",
    "    - Overall, this MLP is doing good work.\n",
    "******************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW3 finished ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
